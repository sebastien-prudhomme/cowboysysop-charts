name: local-ai
appVersion: 1.20.1
description: A drop-in replacement REST API compatible with OpenAI API specifications for local inferencing
home: https://localai.io/
icon: https://user-images.githubusercontent.com/2420543/233147843-88697415-6dbf-4368-a862-ab217f9f7342.jpeg
source: https://github.com/go-skynet/LocalAI
version: 1.3.0
components:
  - name: local-ai
    configmap: |
      preload-models.json: |
        {{- .Values.config.preloadModels | toPrettyJson | nindent 4 }}
    deployment:
      type: deployment
      initContainer:
        command: |
          - /bin/bash
          - -ec
          - |
            mkdir -p /data/generated-audio
            mkdir -p /data/generated-images
            mkdir -p /data/models
        volumeMounts: |
          - name: data
            mountPath: /data
      container:
        env: |
          - name: ADDRESS
            value: ":{{ .Values.containerPorts.http }}"
          - name: AUDIO_PATH
            value: /data/generated-audio
          - name: IMAGE_PATH
            value: /data/generated-images
          - name: MODELS_PATH
            value: /data/models
          - name: GALLERIES
            value: {{ .Values.config.galleries | toJson | quote }}
          - name: PRELOAD_MODELS_CONFIG
            value: /config/preload-models.json
          - name: REBUILD
            value: "false"
        livenessProbe:
          httpGet:
            path: /healthz
        readinessProbe:
          httpGet:
            path: /readyz
        volumeMounts: |
          - name: config
            mountPath: /config/preload-models.json
            subPath: preload-models.json
          - name: data
            mountPath: /data
    image:
      registry: quay.io
      repository: go-skynet/local-ai
      tag: v1.20.1-ffmpeg
    ingress: true
    persistentvolumeclaim: true
    service:
      ports:
        - name: http
          number: 8080
          description: HTTP
    extraValues: |
      config:
        # Model galleries
        galleries: []
          # - name: model-gallery
          #   url: github:go-skynet/model-gallery/index.yaml

        # Models to preload (configure liveness probe initial delay according to model download time)
        preloadModels: []
          # - id: model-gallery@text-embedding-ada-002
          # - url: github:go-skynet/model-gallery/gpt4all-j.yaml
          #   name: gpt-3.5-turbo
          # - id: model-gallery@stablediffusion
          # - id: model-gallery@whisper-1
          # - id: model-gallery@voice-en-us-kathleen-low
tests: |
  import requests


  def test_service_connection():
      url = "http://{{ include "local-ai.fullname" . }}:{{ .Values.service.ports.http }}/v1/models"

      response = requests.get(url)

      assert response.status_code == 200
